---
title: "Age Models in Large Scale Paleoecological Synthesis"
author:
- affiliation: Department of Geography, University of Wisconsin - Madison, Madison, USA
  name: Simon Goring
- affiliation: Department of General Education, Mount Royal University, Calgary, Canada
  name: Andria Dawson (co-authored)
- affiliation: Department of Geography, University of Wisconsin - Madison, Madison, USA
  name: John Williams
bibliography: styles/baconizing.bib
output:
  word_document:
    reference_docx: styles/word_template.docx
    toc: yes
    toc_depth: '3'
  html_document:
    code_folding: show
    fig_caption: yes
    highlight: pygments
    keep_md: yes
    number_sections: yes
    theme: readable
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
dev: svg
highlight: tango
keywords: chronology, geochronology, paleoecology, age-models, Bacon, 210Pb, 14C,
  radiocarbon
csl: styles/elsevier-harvard.csl
abstract: Well constructed chronologies are critical to reliable paleoecological inference and any paleoecological analysis must critically assess the underlying data, age-depth models, and their assumptions and parameters used to build the chronologies. Robust broad-scale syntheses of paleoclimatic and paleoecological data usually require the rebuilding of site chronologies, to ensure that inferences are based on current best practices in age-depth modeling and are not confounded by inconsistencies among sites.  The scope and power of these syntheses are facilitated by 1) advances in Bayesian age-depth modeling approaches and 2) continuing growth of data volumes in community curated data resources in paleoecology.  However, understanding of best practices and parameter settings for these age-depth modeling when working with many records is still poorly understood, and data resources often carry legacy chronologies that must be updated.  This paper uses pollen records and associated chronological controls from the Neotoma Paleoecological Database ([http://neotomadb.org]()) to examine the biases and assumptions made in chronology construction on an aggregate dataset. We examine the challenges of missing uncertainty estimates in ^210^Pb dates, and the use of zero-length hiatuses to account for changing accumulation rates with depth. We also use this exercise to provide prescriptive guidance for chronology construction in the large-scale re-analysis of records.Simple post hoc calibration of interpolated radiocarbon ages results in differences of 31 -- 470 calendar years when compared to newly constructed age models. Age estimates from ^210^Pb dates are linearly related to Bacon model estimates, but Bacon-calculated uncertainties are approximately twice the reported ^210^Pb uncertainty. Sediment deposition times (yrs/cm sediment) show an inflection point and associated five-fold decline at approximately 200 years before present. This shift required setting temporally varying priors for sedimentation rate in Bacon, with a prescribed breakpoint at the settlement horizon. Revised age estimates for the EuroAmerican settlement horizon are, on average, 44 years younger in the new Bacon models than in prior models. The optimal value for section thickness tends to increases total core length.  Caution must still be exercised with age-depth modeling; even with advances in software and data resources, accurate age models require expert judgment and human supervision.  One key need is to better capture and store age-depth model metadata and parameter settings in community data resources, to improve reproducibility and to allow quicker regeneration and updating of these age models as parameterizations and models improve. Other recommendations include the addition of additional kinds of uncertainty models in age-depth models, allowing priors and parameters to evolve through time, extension of models to enable fuller parameter space exploration and optimization, integrating of physical sedimentological data into age-depth models, and the better integration of age-depth models and community curated data resources through shared adoption of common standards.

---

# Introduction

```{r load_libraries, echo=FALSE, message=FALSE, warnings = FALSE, results='hide'}
knitr::opts_chunk$set(cache=TRUE)

# Version numbering and other important parameters are stored in a file `settings.yaml`

source('R/load_packages.R')
```

Advances in paleoecoinformatics are continually improving our ability to store and process large numbers of paleoecological records [@brewer2012paleoecoinformatics;@uhen2013card;@williams2017neotoma], which enables the use of increasingly large data networks to study ecological and climatic processes operating at large spatial scales and at timescales inaccessible to modern observational data [@marlon2017climatic;@bothe2015continental;@abram2016early]. Paleoecological and paleoclimatic databases streamline this process by providing the means to store, curate, and query structured data across specified spatial and temporal bounds. Examples of these databases include NOAA-Paleoclimatology [https://www.ncdc.noaa.gov/data-access/paleoclimatology-data](), Linked Earth [http://linked.earth](), and the Neotoma Paleoecology Database [URL: http://neotomadb.org; @williams2017neotoma]. Generating accurate and precise age inferences using the best available age controls and state-of-the-art age-depth models is a key challenge for scientists using paleoecological data resources for large-scale data syntheses.  Because of the increasingly large data volumes involved (for example, as of `r Sys.Date()`, Neotoma now includes `r nrow(neotoma::get_site())` site-level records, including `r length(neotoma::get_dataset(datasettype="pollen"))` fossil pollen records globally), the central challenge in large-scale regeneration of chronologies is how best to balance speed/automation with careful critical analysis and adjustment of individual age models by experts.  Here we review these issues, assess key sources of uncertainty, and provide examples of solutions developed during our recent data synthesis efforts with the Neotoma Paleoecology Database and the Paleoecological Observatory Network (PalEON).

An emerging practice in paleoecological and paleoclimatic data resources is to store both the original proxy measurements by depth (*e.g.*, the stratigraphic position of vertebrate specimens or micropaleontological assemblages) and the associated age controls, so that age estimates for the proxy measurements can be regenerated as age-depth models and geochronological parameterizations improve [@grimm2014working;@blois2011methodological;@giesecke2014towards].  The chronology for a given record comprises three distinct elements: the age-depth model used for a given paleoecological or paleoclimatic record, the age controls that constrain that age model, and the resultant age estimates for all stratigraphic depths or intervals in that record [@mckay2015linked;@grimm2008neotoma]. Robust chronologies require accurate and precise estimates of absolute ages from radiometric and other age controls, well supported conversion from radiocarbon years to calendar years, age-depth models that make use of prior knowledge [*e.g.* Steno's Law of stratigraphic superposition and rates of sediment deposition and accumulation, @goring2012deposition], and a clear quantification of uncertainty that accounts for both measurement and process uncertainty.

The accuracy and precision of these chronologies are fundamental to paleoecological interpretation, and indeed, geochronology and age models are central to our understanding of the evolution of the earth system [@harrison2016geochronology]. Quaternary scientists are, of course, well aware of the fundamental importance of chronologies, and various papers have explored these issues and the interpretive challenges that can arise from them [@grimm2009magnitude;@liu2012temporal;@trachsel2017all;@blaauw2012out].

Data resources such as Neotoma or LinkedEarth/LiPD can store multiple chronologies for a given record.  Because updating age-depth models takes time and expertise, the stored chronologies do not always conform to the current state of the art in chronology construction.  These legacy age models may have various issues, e.g. 1) no conversion from radiocarbon years to calendar years, 2) conversions that are based on outdated radiocarbon calibration curves, 3) a lack of robust uncertainty quantification, 4) inconsistencies among sites in reconstruction methods, resulting in potential biases. One shortcut workaround used in Neotoma for its legacy chronologies expressed in radiocarbon years is a *post hoc* conversion of individual age estimates to calendar years.  This practice is sufficient for first-pass queries to discover and retrieve data by temporal bounds, however this is insufficient for research-quality data syntheses since it produces systematic offsets on the order of hundreds of years (Fig. 1).

```{r get_cores, echo=FALSE, message=FALSE, results='hide', warning=FALSE}

source("R/getNAcores.R")
source("R/get_allpublications.R")
source("R/get_allchronologies.R")
source("R/build_newchrons.R", echo = FALSE)
source("R/figures/plot_recal_diffs.R")

all_downloads <- north_american_cores(settings$version)
pubs <- get_allpublications(all_downloads, settings)
chronologies <- get_allchronologies(all_downloads, settings)

# Generate age models using BChron:
# Get chronologies and rebuild, but drop som specified sample sites
# because of strange behavior:

age_seq <- seq(1000, 21000, by = 1000)

new_chrons <- build_newchrons(all_downloads, chronologies, settings) %>%
  filter(!core %in% c("Chalko Lake", "Aghnaghak", "Pittsburg Basin",
                      "Lac Ã  l'Ange", "Marl Pond", "Cheyenne Bottoms",
                      "San Agustin Plains")) %>%
  group_by(handle) %>%
  mutate(max = findInterval(max(age.lin, na.rm = TRUE), age_seq)) %>%
  na.omit

plot_recal_diffs(new_chrons)
```

<object type="image/svg+xml" data="figures/agediff_plot_final.svg" style="width: 100%;">
Differences between age models and direct recalibration.
  <!-- fallback image in CSS -->
</object>

**Figure 1**. *Diagram of two methods for generating calibrated dates from radiocarbon age-models.  (a) Each age (in radiocarbon years) is calibrated directly (red arrows) from an existing model (black dashed line) or (b) the age models is reconstructed using linear interpolatation (red dashed line) from calibrated radiocarbon ages (red line).  Negative values indicate that recalibration of interpolated ^14^C dates followed by linear interpolation of calibrated ages provides systematically older ages than direct recalibration of interpolated ages. (d) Using the chronological controls of the default age model from Neotoma records, calibrate chronological controls reported in radiocarbon years, and then use linear interpolation.  Any records with age-reversals were rejected to simplify this illustrative example.*

Hence, an early step in any large-scale data synthesis is to review the extant chronologies associated with the records at hand and update them as needed. Ideally, these updated chronologies should be placed back into the archival data resources, to maximize comparability of results across studies, reproducibility, and reuse by other researchers. Recent examples of large-scale paleo-synthesis analysis have focused on standardizing age models for records within a database  and establishing regional benchmarks. Age model standardization in Europe relied on the Clam software , as did efforts with the North American Pollen Database [@blois2011methodological].

At the same time, Bayesian approaches are becoming the new standard in age-depth modeling, because of their ability to return robust uncertainty estimates, and to incorporate knowledge about system processes and prior knowlege into the sedimentation models [*e.g.*, @blaauw2011flexible;@ramsey2013recent;@parnell2016package]. Although many site-level papers have adopted Bayesian methods, few large scale syntheses have done so [e.g., the ACER database used Clam: @sanchez2017acer].

A number of issues arise during the large scale generation of many chronologies. First, building an age-depth model requires expert judgement: there are enough complexities in sedment stratigraphies and geochronological data that fully automated plug-and-play solutions do not yet have a high probability of returning accurate age inference.  However, the subjectivity and flexibility inherent to age-depth modeling may introduce additional "researcher degrees of freedom" that could lead to greater rates of false-positive relationships in paleoecological research [-@blaauw2012out]. Bacon, for example, contains various parameters, priors, and settings such (e.g., sediment accumulation rates) that may be unknown, or complex to implement at large spatial or temporal scales [@sanchez2017acer].

Reliable sediment age estimates require accurate dating of high quality stratigraphic control points, well supported conversion from radiometric (often radiocarbon) to calendar years, robust and reliable models that mehcanistically or empirically represent the underlying process of sediment deposition and accumulation, and clear quantification of uncertainty that is able to take into account measurement and process uncertainty.

Second, many different kinds of age controls may be used to constrain age-depth models, each with its own methodological underpinning and associated sources of uncertainty: accurate quantification of age estimates and uncertainty must incorporate all these sources.  These include radiometric dates or other absolute age estimates (*e.g.*, ^14^C, ^210^Pb), stratigraphic horizons (*e.g.*, modern core tops), or biostratigraphic events (*e.g.*, changes in pollen assemblages associated with dated changes on the landscape).  Sources of uncertainty in radiometric dating include analytical errors in laboratory dating processes [@ward1978procedures], the calibration of certain age types [*e.g.*, radiocarbon to calendar year calibration: @reimer2013selection], choices among calibration models, and potential differences between the ages of dated material and the age of deposition of the sediment matrix [@blois2011methodological].

 The magnitude and sources of uncertainty in stratigraphic markers varies.  For sites with continuous deposition, the core top age can be assumed to be the year (or decade) of sampling, while tephras are often widespread and well dated.  However, not all tephras are well dated and not all tephra deposits at a given site can be confidently matched to known eruption events or previously dated tephra deposits [@watson2016peatlands;@mackay2016mid]. Biostratigraphic age controls are determined by the identification of changes in biological proxies  that correspond to well-dated events, e.g. EuroAmerican land clearance [@mcandrews1988human]. Although identification of these events usually requires on visual identification by experts, the uncertainty in these estimates can be quantified through expert elicitation [@dawson2016quantifying;@kujawa2016theeffect] and assigned to changes in biological proxies that correspond to well dated events such as EuroAmerican land clearance in eastern North America [@McAndrews1968]. Further uncertainties arise from variations in sample density [@liu2012temporal], and questions over whether biological events were synchronous across sites, time-transgressive, or a temporal mosaic [@bennett2002determining;@davis1981outbreaks;@williams2011extrinsic;blois2011methodological]. Large networks of sites with well-constrained chronologies can provide answers to these questions and constrain the temporal uncertainty associated with using biostratigraphic control points in age models [@blois2011methodological].

```{r, plot_chron_change, fig.width=6, echo=FALSE, message=FALSE, results='hide', warning=FALSE, dev='svg'}

source('R/figures/ageplot_histogram.R')

hists <- chronology_type_histogram(all_downloads, pubs, settings)
```

<object type="image/svg+xml" data="figures/histograms_cleaned.svg">
  Histograms of age model types against year of publication
  <!-- fallback image in CSS -->
</object>

**Figure 2**.  *Number and type of default chronologies for North American pollen records in the Neotoma Paleoecological Database based on the original year of publication for the dataset.  Within Neotoma the default dataset chronology may be updated by subsequent researchers when this information is provided to a data steward.*

Here we describe and review the methods used to generate a large number of chronologies and quantify the effects of decisions made on aggregate outcomes.  This effort serves the dual goals of documenting the decisions made, and also reviewing and illustrating the challenges inherent to this effort, as a guide for other researchers interested in pursuing similar efforts.  All samples were drawn from the Neotoma Paleoecological Database: all chronologies were built using the age-depth model.  These chronologies were built to support efforts to reconstruct centennial- to millennial-scale compositional changes in forest dynamics in the upper Midwestern United States (UMW) with uncertainty using the STEPPS pollen-vegetation model [@dawson2016quantifying].  We outline the decision making process around age-model parameter selection, summarize differences between the original chronologies and the new chronologies, and highlight best practices for chronologies within large-scale synthesis.  We also identify limitations of current methods, that could serve to improve chronology construction in the future.

# Key Issues in Generating Age Models from Neotoma

## Use of *posthoc* calibration of individual ages in radiocarbon chronologies

Many legacy pollen records in Neotoma still record chronologies using only radiocarbon years (Figure 2). The transition from age models using only radiocarbon years to those with calibrated radiocarbon years within Neotoma is dramatic.  The final radiocarbon model added to Neotoma was created in 1998.  Along with this transition, a second transition from simple linear models to more complex models using flexible Bayesian methods exists, although this is not shown.

While not the preferred method, direct recalibration of interpolated ages does occur within the Neotoma software ecosystem as a *post hoc* calibration of the derived age estimates for individual samples. For example, the temporal search function within the Neotoma Explorer (http://apps.neotomadb.org/explorer), Tilia (http://tiliait.org) and the Neotoma API (http://api.neotomadb.org) all use a lookup table that directly matches calendar years before 1950 to radiocarbon years if no calibrated chronology exists for a record. However, this process results in systematic biases in both synthetic data and in the actual Neotoma data, on the order of approximately 125 years across the last 20000 cal yr BP, but upwards of 500 years during some millenia (Figure 1).  Hence, this *post hoc* approach is suitable for most data discovery and outreach applications, but is clearly unacceptable for most research-level data syntheses.

## Choice of Age-Model Type and Software

Estimating age-depth relationships and uncertainties requires that decisions be made about the type of age modeling approach, choice of software implementation, suitable chronological controls and model parameters [@blois2011methodological;@grimm2014working;@giesecke2014towards]. We here pursue Bayesian approaches for their ability to flexibily estimate the ages of pollen samples with robust uncertainty. Several Bayesian age modelling software packages exist, including Bacon, Bcal, Bchron, and Oxcal. We use Bacon because it 1) implements a Bayesian framework that estimates sample age posteriors, 2) is widely used by paloecologists [*e.g.*, @charman2015drivers;@wang2017southern], and 3) accounts for some of the key components in the sediment deposition and accumulation process. Using Bacon to estimate age-depth relationships requires the specification of: 1) chronological controls, which include radiometric dates, biostratigraphic markers, and their uncertainty, 2) priors on the accumulation rate and memory, 3) values for the resolution and structure of divisions within the sediment core (section thicknesses and hiatuses). To ensure a consistent methods and age inferences among sediment cores in the UMW domain, we developed a set of standard decisions for each of these three components, and analyze the effects of these decisions on age estimates and uncertainty.

## Choice of Age Controls and Types

Neotoma contains `r nrow(neotoma::get_table('ChronControlTypes'))` age control types ([http://api.neotomadb.org/v1/dbtables/ChronControlTypes]()), including various pollen stratigraphic controls, radiocarbon and other isotopic dates and marine isotope stages.  Since analysis in Dawson *et al*. [-@dawson2016quantifying] was focused on reconstructing vegetation compositional dynamics in the late-Holocene, most chronological controls presented here are appropriate for teporal domains from the present back to 10^1^ to 10^5^ years before 1950, including ^210^Pb, ^137^Cs, and ^14^C dates, as well as biostratigraphic dates associated with events of known or inferred dates, such as historical fires and the *Tsuga* decline (*cf*. [@bennett2002determining;@booth2012decomposing]).  Core tops are often used, and have highly certain dates, however, several older records use interpolated dates for the core top when sediment was lost in the coring process.  These cores should be treated with caution, and this is often noted in the core description.

```{r get_chroncontroltypes, results = 'hide', echo = FALSE, warning=FALSE}

source("R/get_allcontrols.R")

controls <- get_allcontrols(all_downloads, settings)

control_type <- controls %>%
  map(function(x) {
    cty <- as.character(x$chron.control$control.type)
    return(
      data.frame(controlid = x$parent$dataset.id,
                 control = cty,
                 stringsAsFactors = FALSE))
  }) %>%
  bind_rows() %>%
  group_by(control) %>%
  summarise(count = n())

knitr::kable(control_type[order(control_type$count, decreasing = TRUE), ])
```

## Chronological Uncertainty

Methods for assessing and managing radiocarbon uncertainty in large-scale data syntheses are well established [@blois2011methodological], however the use of ^210^Pb and biostratigraphic dates has been less well established. One challenge with ^210^Pb dates is that, because uncertainty of ^210^Pb dates are small (sometimes less than 1yr), the uncertainties are often unreported, or not stored in paleoecological databases such as Neotoma.  Another issue is that the analytical uncertainty associated with a ^210^Pb date is an underestimate of the derived age inference.

Biostratigraphic events usually require expert identification, with uncertainty arising from both disagreement among experts in the stratigraphic placement of the event [@dawson2016quantifying;@kujawa2016theeffect] and the age of the event [@bennett2002determining].  Futhermore, these events may be time transgressive [@blois2011methodological].

### Dealing with zero-value ^210^Pb errors

Bacon requires that all age controls be associated with defined errors. Historically, some ^210^Pb data entered into Neotoma were entered without error reporting.  Of the 398 ^210^Pb age controls in Neotoma (as of `r Sys.Date()`), 148 have no error reported (Figure 3).  Binford [-@binford1990calculation] reports *"Ninety-five per cent confidence intervals range from about 1 -- 2 years at 10 years of age, 10 -- 20 at 100 years, and 80 -- 90 at 150 years old."*  Using this assessment we fit a smooth linear function to assign 95% confidence intervals for all ^210^Pb dates with missing uncertainty data.  These confidence intervals were then divided by 2 (and rounded up to the nearest integer) to obtain standard deviations to be used in the Bacon model (Figure 3).

```{r plotlead210, echo=FALSE, message=FALSE, results='hide', warning=FALSE, dev='svg'}
source("R/get_allgeochron.R")

all_geochron <- get_allgeochron(settings)

source("R/lead_plotting.R")

lead_plots(all_geochron, all_downloads)
```

**Figure 3.** *Reported uncertainty for ^210^Pb dates within Neotoma, by age (upper panel), with the total count of unassigned samples by age bin (lower panel).  In our age-depth models, estimated uncertainty, using a model relating reported ^210^Pb uncertainty to age, is then assigned to all ^210^Pb dates with unreported uncertainty. Present is defined as radiocarbon present, or 1950 CE.*

### Identify biostratigraphic events and assigning ages

Biostratigraphic events have been used extensively as chronological controls within age models, but few guidelines or standard methods exist for formally identifying the events. The *Ambrosia* rise is a widespread phenomenon in the eastern United States, and elsewhere, that is a signal of Euro-American settlement, land clearance and the initiation of intensive agriculture in the region [@McAndrews1968; @mcandrews1988human]. In the UMW, significant increases in *Ambrosia*, *Rumex*, and/or Poaceae are typically coincident with the settlement horizon, making this event suitable as a biostratigraphic chronological control. To reduce expert bias in identification of the settlement horizon and the selection of the 'pre-settlement' sample just below this horizon, we asked a team of experts to identify pre-settlement samples based on pollen diagrams depicting proportional changes as a function of depth for key indicator species and the ten most abundant arboreal taxa, with no temporal scale.  More details of this procedure are available in Dawson et al. [-@dawson2016quantifying] and in Kujawa et al. [-@kujawa2016theeffect].

The elicitation exercise provides an independently assesed estimate of biostratigraphic change in the pollen records that can be used as a biostratigraphic marker. Gridded Public Land Survey (PLS) datasets in this region provide a historical record of the time of land surveying [@goring2016novel], which was usually a precursor to intensive land clearance for settlement and agricultural and pastoral land use. However, using the dates of PLS surveys to set the date of the *Ambrosia* rise may miss earlier land clearance signals by Native Americans or early European explorers.  The synthesis of PLS data and mapping of forest composition in Goring et al. [-@goring2016novel] provide 8km gridded datasets. Metadata for each gridcell includes the PLS sampling year for the individual points within the cells.  Here we substract 50 years from the PLS survey date to assign the age of a "pre-settlement" sample identified in each core, with a symmetric age uncertainty (stanadard deviation) of 50 years.  A further refinement to this method would include asymmetric uncertainty, because, in the case of the settlement horizon, we know the upper age estimate for likely land use (*i.e.* the timing of PLS survey), but not the earliest age estimate.

Five sediment cores were from lakes or mires located within grid cells without digitized PLS data. In these cases, the surrounding grid cells are used to estimate the most recent sampling year. One site in the Upper Peninsula of Michigan was assigned a maximum sampling year of 1860. The four remaining cores were in the Lower Peninsula of Michigan, and were assigned a maximum year of sampling of 1840.

## Bacon Settings

### Accumulation Rate Priors

Bacon provides a default accumulation rate for all depths based on a prior survey of Holocene accumulation rates in eastern North America [@goring2012deposition].  Empirical age-depth curves suggest that the age-depth relationship is usually smoothly varying, with stretches of roughly constant rates of sediment deposition and quasi-linear age-depth models, and other stretches with non-linear variations caused by on-going sediment dewatering and compaction in the uppermost sediments [@goring2012deposition], basin shape [@bennett2016interpretation] and patterns of deposition and sediment transport operating on longer time scales [@goring2012deposition;@webb1988rates] and acceleration of watershed erosion rates during the Great Acceleration [@knox2006floodplain;james2013legacy]. Many sites show an inflection point in sedimentation rates at or around the EuroAmerican settlement horizon in the UMW, with faster rates of sedimentation after (approx. $\bar{x}$ = 4 years cm^-1^ sediment accumulation) than before ($\bar{x}$ = 12 years cm^-1^), likely due to a combination of both lower compaction in upper sediments and changes in land use and erosion [@goring2012deposition]. In this analysis, we reassessed the prior estimates of sediment accumulation rate from Goring et al. [-@goring2012deposition], because our analyses focused on a narrower geographic and temporal range.  Our analysis provides better constraints on the rates of sediment accumulation before and after settlement, to help constrain PalEON age models for the last two millennia.

To generate accumulation rate priors for the UMW we estimated accumulation rates by pooling the mean age and change in depth for adjacent chronological markers. These accumulation rates were pooled into "modern" and "pre-settlement" groups. For each group we calculated a mean equal to the empirical mean of accumulation rates for that time period, and a variance equal to double the empirical variance from the grouped accumulation rates.  Doubling the empirical variance represents a conservative approach to modeling uncertainty, in that it accounts for additional variability in accumulation rates beyond that observed in the data.  This more conservative approach allows the priors to be more uninformed, so that age-depth models at individual sites are not too tightly constrained to regional priors.

The "modern" pool of accumulation rates was used to set the prior for all sediments above the EuroAmerican settlement horizons assigned through the expert elicitation exercise, while the "pre-settlement" pool of accumulation rates was used to set the prior for a) all sediments below the settlement portion in cores with an identified horizon and b) for the entirety of cores without identified settlement horizons. Cores with two priors were assigned an "instantaneous" (10yr) "hiatus" at the pre-settlement sample depth; user specification of 'hiatuses' is the mechanism used in Bacon to allow users to specify core segments with different priors [@blaauw2011flexible].

### Determining section thickness

Bacon works by diving a core into sections whose lengths are determined by the user [@blaauw2011flexible]. Sections are the atomic unit of a Bacon age-depth model, and various parameters are fit within and among sections.  In particular, the `memory` parameter defines the autocorrelation of the accumulation rates between adjacent sections, hence serving as a key control on the flexibility of the Bacon age-depth model.  Flexibility can also be set by choosing section thickness (which effectively sets the number of sections, for a core of fixed total thickness), because a model with large section thicknesses will have fewer overall sections, and so will be less flexible. However, narrow section thicknesses result in very large run-times, and may show other, unanticipated problems associated with finding fits in multi-parameter space.

Dividing a core into sections is an approximation of time discretization [REF - Andria?], abstracted through the process of deposition.  Consistent section widths across all cores (and thus consistent discretization) should be a goal. However, the internal unmeasurable variability in sedimentation rates, and uncertainty in the age-depth models themselves, makes it difficult to implement consistent section thicknesses.  To provide prescriptive widths, but still allow flexibility as needed in the Bacon modelling, each core was run with widths of 5, 10, 15 and 20cm.  Model fit was assessed visually, and the best-fit model was subsequently chosen to be the default calibrated age model for that core.

# Results

## Age Controls

### ^210^Pb Errors

```{r, lead_comparison, results = 'hide', echo = FALSE, warning=FALSE, dev='svg', eval=TRUE, message=FALSE}

source("R/lead_ages.R")
comp_doc <- compare_lead(coredir = "../bacon-agegen",
                         all_geochron,
                         settings = settings,
                         param_file = "../bacon-agegen/data/params/bacon_params_v1.csv")

model  <- lm(I(1950 - bacon_age1) ~ age, data = comp_doc[[2]])
uncert <- lm(bacon_error1 ~ e.older, data = comp_doc[[2]])

comp_doc[[1]]
```

**Figure 4**. *Reported and estimated ^210^Pb ages from the Bacon models generally show strong accordance.  However, uncertainties within the constructed Bacon models at the depths of the ^210^Pb samples are higher for Bacon models (y-axis) than from the original estimates for models including ^210^Pb dates (x-axis). The autoregressive nature of the Bacon model, the influence of the memory parameter, and the nature of the Bayesian model itself mean that uncertainty is propagated through the core, and as such low uncertainty in the individual ^210^Pb dates (x-axis) does not result in low Bacon uncertainty.*

Bacon-modeled ages are linearly relatedto ^210^Pb ages, but with the Bacon ages older than the ^210^Pb ages (slope = `r round(model$coefficients[2], 2)`, p < 0.01; Figure 4).  Uncertainty estimates for the Bacon chronologies are also consistently larger than the ^210^Pb error estimates for the point samples and the difference increases with depth (slope = `r round(uncert$coefficients[2],2)`, p < 0.01).

Only three lakes in the region had age models that included ^210^Pb dates and reported estimates of uncertainty for the chronology. Bacon age estimates for these records show higher uncertainty than the original age model, but the difference is site-specific (Figure 5).  For Crooked Lake [@brugam1997holocene] the uncertainty difference is high and consistent with depth/age (triangles, Figure 5), while for Fish Lake [@umbanhowar2004interaction] the difference is small (squares; Figure 5).  Brown's Bay shows the highest uncertainty, but only at the deepest depth (circles; Figure 5). This analysis illustrates how prior age modeling approaches tend to underestimate age uncertainty relative to Bayesian approaches such as Bacon, but that the degree of difference varies widely among sites and within cores. This indicates that analysis that aims to examine spatio-temporal patterns must consider age-depth model construction as a source of variability, and should aim to standardize models to reduce this variability.

```{r, error_by_age, results = 'hide', echo = FALSE, warning=FALSE}

source("R/figures/comp_lead_plot.R")

comp_lead_plot(comp_doc)
```

<object type="image/svg+xml" data="figures/lead_comp_final.svg">
  Comparison of 210Pb dates measured and reconstructed error at those depths.
</object>

**Figure 5**. *For the three cores within the region with both reported ^210^Pb and reconstructed Bacon uncertainties, the latter are consistently higher, although the magnitude of the difference varies by record.  Fish Lake shows the smallest difference, while reconstructed ages for Brown's Bay shows the largest difference.*

### Expert Elicitation

```{r, elicitation_plot, echo = FALSE, message = FALSE, warning = FALSE, error = FALSE}
source("R/elicitation_plot.R")
# Double check that this is the right depth. . .
elicitation_plots <- expert_elicitation()
```

The modeled ages from the original Neotoma age models frequently were older than the biostratigraphic ages assigned based on the dates for the Public Land Survey.  Of the 163 records with assigned settlement dapths and with ages obtained from the elicitation exercise, 55 of the original age models have a modeled ages at the assigned settlement horizon that are younger than 1800 CE, while only 17 of the Bacon models have a modeled age for the settlement horizon younger than 1800 CE. Age estimates from the Bacon models showed better affinity to the assigned biostratigraphic dates, which is expected given that these biostratigraphic ages are used as constraints for the Bacon models.  The Bacon models are, on average, 44 years younger at the settlement horizon than the original models. This age difference would result in faster estimated rates of change for pollen in the Bacon models than for the post-settlement sediments.

```{r, echo = FALSE, message = FALSE, warning = FALSE, error = FALSE, dev = 'svg'}
elicitation_plots[[1]]
```

**Figure 6**. *The relationship between assigned 'settlement' horizons, based on Public Land Survey records and the expert elicitation exercise, and the modeled age of the horizon within the final age-depth model for each individual record.  The settlement horizon plotted against the modeled age within the original age model (left); and against the newer Bacon model (right).  A best fit linear regression is plotted in blue, with a 1SE envelope in gray. The negative relationship in the original models may reflect an over estimation of sedimentation rates in upper sediments as a result of linear age-model fits. Higher variability in the orginal relationship may represent greater inter-researcher variability in settlement horizon estimation.*

Linear models relating assigned settlement ages to modeled ages for the original age models show a negative slope (Figure 6). This may be because many of the original linear models over-estimate sedimentation rates in the upper sediments since they assign an inflection point at the horizon. Higher variability is likely a result of both variability in detecting and assigning the settlement horizon among researchers, but also in the process for assigning the age associated with settlement regionally. Researchers may have used historical documents, oral histories or other records. The use of the standardized PLS dates in the new models reduced this source of variability.

## Bacon Settings

### Accumulation Rate Priors

**Table 1**. *Empirical estimates of accumulation rates in the Upper Midwestern United States from Neotoma records.*

```{r, get_acc_rates, echo = FALSE, message = FALSE, warning = FALSE, error = FALSE, results='as-is'}

source("R/acc_rate_priors.r")
accs <- get_accs(bacon_params, path = "../bacon-agegen/Cores/")

means <- accs %>%
  group_by(era) %>%
  summarise(mean  = mean(rate_sqrt),
            var   = var(rate_sqrt),
            rate  = fitdistr(rate_sqrt, 'gamma')$estimate['rate'],
            shape = fitdistr(rate_sqrt, 'gamma')$estimate['shape']) %>%
            mutate(era = ifelse(era == 'modern',
                                   'Post-Settlement',
                                   'Pre-Settlement'))

knitr::kable(means, digits = 2,
             col.names = c("Period", "Average (yr/cm)",
                           "Variance", "Gamma Rate", "Gamma Shape"))
```

Accumulation rates (*yr/cm* of sediment accumulation) for records in the region show clear differentiation between accumulation rates within the last 200 years and accumulations prior to the last 200 years. Means and variance are presented in **Table 1** along with the Gamma rate and shape parameters. Deposition times (the mean *yr cm^-1^* deposition) change dramatically, dropping by five-fold in the modern period.

```{r, get_acc_plot, echo = FALSE, message = FALSE, warning = FALSE, error = FALSE, dev = 'svg'}

plot_acc_rates(accs)

```

**Figure 7**. *Sediment deposition times for cores in the study region with samples in the last 2000 years (in calibrated radiocarbon years, with 0 at 1950 CE).  The upper panel shows the deposition rate in years cm^-1^ against the interval midpoint age in calibrated radiocarbon years. The dashed vertical line indicates 1850 CE, the approximate date used to represent major land-use change as a result of EuroAmerican settlement. Note the strong change in deposition rates between the periods before and after EuroAmerican settlement. The lower panel shows the distribution of accumulation rates for the pre- and post settlement eras, highlighting the difference in central tendency.*

Deposition rates increase with time across the pre- and post-settlement interval (Figure 7a). Bacon does not support the use of time-dependent priors, except through the use of sequential hiatuses. This can create challenges for the pre- and post-settlement age models, because the post-settlement sediment sequences are often short and perhaps only constrained by core top and the settlement horizon, and so are not amenable to multiple sections above the settlement horizon. Overall, sequential hiatuses are problematic and highly site-specific mechanisms for setting time-varying priors because they depend on sampling intervals and the length of the pre- and post-settlement sequence within the core.

### Section Thickness

```{r, get_thickness, echo = FALSE, message = FALSE, warning = FALSE, error = FALSE}

source("R/thick_model.R")
model_plot <- allan_thick(coredir = '../bacon-agegen',
                          paramfile = '../bacon-agegen/data/params/bacon_params_v1.csv')

```

Bacon models were fit with section thicknesses for values of 5, 10, 15 and 20cm for each core (Figure 8).  Optimum section thickness was assigned from the best fit model and all four section thicknesses were chosen for some subset of models, with 5cm the most common model thickness (`r sum(model_plot$thick$thick == 5, na.rm=TRUE)` of `r nrow(model_plot$thick)` cores), and 10 and 15 the least common section thickness (each `r sum(model_plot$thick$thick == 10, na.rm=TRUE)` of `r nrow(model_plot$thick)` cores).  A generalized linear model (GLM) using a gamma family shows a significant relationship between total core length and best-fit section thickness ($F_{1.241}$ = `r round(model_plot$glm$F[2],1)`, p > 0.001), with wider section thicknesses tending to be more often optimal for longer cores. This relationship between core thickhness is strongest for the cores with section thickness set to 5cm, which were preferentially chosen for cores <3m long (`r sum(model_plot$thick$core_length1 < 300, na.rm=TRUE)` of `r nrow(model_plot$thick)` cores).  Nevertheless, the distribution of best-fit thicknesses (Figure 8) also appears to indicate that many shorter cores are well served by wide section thicknesses.  The GLM accounts for only 26% of total deviance, and should be treated as indicative, not prescriptive.

```{r, plot_thicknessmodel, echo = FALSE, message = FALSE, warning = FALSE, error = FALSE, dev = 'svg'}

model_plot[[1]]

```

**Figure 8**. *Bacon section thickness as a function of total core length for best-fit Bacon models on each of the 282 sediment cores with reconstructed age models from the upper Midwestern United States used in this study.  A curve (blue line) fit with a generalized linear model with gamma family indicates the predicted relationship between maximum core depth and the best-fit core thickness (gray shading represents 1 standard error).*

# Discussion

Large scale synthesis of paleoecological records relies on our ability to distinguish synchronous, time-transgressive, and asynchronous events at a range of spatial and temporal scales. Standardized age models, across datasets reduces a significant source of variability and bias that can lead to incorrect ecological inference. Coupling this standardization with Bayesian approaches can improve the ability of researchers to incorporate temporal uncertainty into assessments of past vegetation dynamics and the influence of climatic and biotic factors on these dynamics.  The continued growth of large community data resources such as Neotoma and the ongoing advances in age-depth modeling means that chronologies will have to be regularly updated, and for increasingly large data volumes.  Our approach in this paper has been intended to illustrate some of the key decisions and challenges with current resources, and also, we hope, can serve as a roadmap for other efforts seeking to build well-constrained chronologies as a foundation for large-scale synthesis projects in paleoclimatology, paleoecology, and biogeography.

One general lesson is an old one:  caution must be exercised in undertaking the batch re-calculation of chronologies. Even with advances in method, there is still no substitute for critical analysis.  Many forms of machine learning can be parsed into those that can be unsupervised by humans and those that require human supervision at some stage of the process; age-depth models still fall very much in the latter category. Site-level effects on deposition rate and the accuracy of age controls can significantly affect age-depth relationships, presenting a challenge for paleoecologists when examining pollen accumulation and interpreting model results. When working with aggregate data it is possible to lose sight of the importance of site-level effects; the potential benefits of batch runs with newer techniques might make a researcher overlook the peculiarities associated with individual records. Taking time to examine results in the context of the original publications is critical to evaluating the quality of a record. In this exercise, a number of records were rejected, a number of records had modifications made and some peculiar records were retained based on documentation within the primary literature. There is no alternative to knowing your data well.

## Modelling Recommendations

This work has highlighted a number of future opportunities for age-depth model development.  The last decade has seen rapid improvements in modeling software and our understanding of the limitations of chronologies [@trachsel2017all;@telford2004all], but work remains.  This work can be broadly categorized into *Parameters*, *Process* and *Product*:

### Parameters

Most modern age-modeling software provides for the use of only a single uncertainty model for age estimates, normally distributed (or Student's $t$) error. (Note, however, that age-depth models relying on radiocarbon dates can translate normal This is at odds with certain age constraints, such as the "modern" sample, which has an absolutely known age, or, in this study, the pre-settlement horizon which provides a fixed "older" date, but an uncertain younger boundary, and as such reflects a truncated distribution. Providing a broader range of uncertainty distributions could improve modelling of certain features used as chronological controls in age models.

Another need is to allow these parameters to vary through time.  This work has reinforced earlier findings [@goring2012deposition;@bennett2016interpretation;@webb1988rates] that  some sedimentation rate change through time, so prior estimates of sedimentation rate need similar flexilibility. The autocorrelation of accumulation rates (in Bacon, the memory parameter) may also change through time, as the sediment source changes, or, as a result of long term changes in precipitation variability evident in regional climate reconstructions [@cook2010megadroughts;@marlon2017climatic;@newby2014centennial]. Currently, accomodating changes in any parameter through time requires the use of a zero-length hiatus in Bacon, and may be impossible with other software. Allowing time/depth varying parameters using priors drawn from (for example) Neotoma [@williams2017neotoma] or the Europrean Pollen Database [@brewer2016late] would provide significantly more control for chronology models.

Another useful advance would be to develop software systems for more systematic exploration of age model settings and parameters and optimal parameter selection. Given the number of parameters required to fit models, and their interactions, it is only natural that, at times, changes in parameter values can have non-intuitive changes in model performance or fit. Changing memory parameters should increase or decrease the flexibility of models, but section thickness can also influence flexibility, and these may have interacting effects. By allowing users to pass vectors of values for parameters it may be possible to produce a parameter space of fits with a single call, from which the best-fit model may be selected.

## Process

Sedimentation is a physical process that is driven by climatic factors, changes in sediment source, changes in basin size or shape, and autotrophic effects. Artifacts in the modeling of sedimentation rates may be affected by the process of coring (e.g. as a result of compaction during coring) and in generating composite cores when multiple drives are used to collect a complete sedimentary sequence (e.g. with gaps between cores or differences between cores in sedimentation rates). Information relating the way multiple drives are spliced is rarely included in data records, but can introduce depth uncertainty in the composite core. Most of this information about core splicing is lost during publication.  Work on fit assessment is being undertaken with CoreWall [http://www.corewall.org]() and independently within the ODP program (CLIP: [http://www.ldeo.columbia.edu/BRG/ODP/ODP/CLIP/clip.html]()), but this information is not yet being introduced into age-depth modelling software.

External influences on sedimentation rate may appear in secondary proxies, for example, grain size [ref] or taxonomic composition in peat sequences [ref]. Currently there is no ability to use this physical sedimentological data to constrain age model accumulation or flexibility, e.g. by placing a high prior likelihood of changed sedimentation rate at an observed shift from Pleistocene mineralogenic silts to Holocene gyttjas. Providing these secondary controls would add additional complexity to age models, but could improve overall model fit, particularly as XRF and other associated measurements from core logs become more commonplace and accessible.

### Product

The age model has always been a fundamental basis for inference  paleoecological studies.  Accurate specification of uncertainty and full reproducibility of paleoecological inference both require specification of age models and storage of this information. As such, the decisions that go into age-model construction must be preserved in a codified manner [@grimm2014working]. The development of widely accepted provenance standards (e.g., W3C PROV), and their adoption and promotion within large institutions [REF] mean that this information can be preserved, but adoption of these standards remains a challenge. Community standards for temporal data in the geological sciences are at the early stage of development REFS, and more work is needed to refine them and increase their adoption. Community support for standards, and the development and continued participation within distributed research networks such as the Earth Sciences Information Partnership, Cyber4Paleo or EarthRates, are necessary for developing community standards for temporal inferences. As we get better at fully preserving age models and their derived inferences, we will be able to more quickly update our age inferences as new advances in geochronology and age-depth modeling become available. For example, as the IntCal curve improves REFS, Bacon models that have been preserved in Neotoma with their full suite of parameters may be automatically re-run, and clearly attributed as more recent versions, without the need for painstaking expert assessment of individual age-depth models. This was a goal of the PAGES Age Modelling meeting [@grimm2014working], but its implementation remains incompletely realized.

**Table 2**. *A summary of challenges and solutions for the process of age-modelling within the paleoecological community.*

| Challenge | Solution |
| ------------------- | -------------------------------------- |
| **Parameter** ||
| Age uncertainties vary in the shape of their distributions. |  Allow uncertainty models to include other distributions, including truncated distributions. |
| Accumulation rates change through time but priors are fixed. | The current solution is to use 'zero-length' hiatuses, which serve to reset the accumulation rate, but allowing models of change based on empirical studies would improve fit. |
| Parameter values can have significant, but unintuitive effects on model fit   | Allowing models to accept vectors of possible values may improve fit and provide a better understanding of the interacting relationships between model parameters.   |
| **Process** ||
| Uncertainty in depth is not represented | Estimates of overlap within composite cores, based on correlation from geochemical or visual cues may be included |
| Models don't use secondary information. | Secondary parameters may be used to indicate rapid changes in memory, or accumulation. |
| **Product** ||
| Age models require significant oversight |  Codify certain decisions, provide testing suites for fit parameters. |
| Ensuring that model outputs are clear and the decisions made about parameters are justified.  | Improved uptake of reproducible workflows and use of provenance tools. |
| Managing records with multiple age models, with varying parameters. | Decision making processes must be codified for the use or rejection of models when multiple "best-fit" models exist with varying parameters. |

## Future development

The tools and techniques for generating age models continues to increase.  BChron [@parnell2016package], Bacon STAN ([https://github.com/andrewdolman/baconr/]()), CSciBox ([https://www.cs.colorado.edu/~lizb/cscience.html]()), OxCal [@ramsey2013recent] all exist as alternative tools, and geochronR ([https://github.com/nickmckay/GeoChronR]()) exists as a resource for managing age models in the R programming environment. It is unlikely that the community will select a single resource for building chronologies.  A key advance forward is the closer integration of these various age-modeling systems with community-curated paleodata resources such as Neotoma, to enable faster generation of better chronologies.  This in turn will be facilitated by the adoption of standards to improve interoperability of data resources and models.  Ultimately, this capacity to build better age models more quickly helps our community achieve the goal of macro-scale paleoecological research from networks of site-level paleoclimatic and paleoecological records distributed across regions, continents, and the globe.  Because chronology construction is an integral part of paleoecological workflows, better standardization and acceleration of these methods can lead to improvements in our overall understanding of many of the macro-scale research questions that drive us as a community and as individuals.

# Conclusions

Regeneration of chronologies is usually a first and critical step in any large-scale data synthesis using Quaternary paleoecological records. Careful attention to chronology development can result in substantial changes to site-level chronologies, and systematic shifts in the estimated timing and expression of paleoecological and paleoclimatic events. Here we illustrate some of the key methods and decisions associated with a rebuilding of chronologies 282 fossil pollen records drawn from the Neotoma Paleoecology Database and using the Bacon age-depth model.  These reanalyses show that uncertainty estimates from older age models and point-level age controls are low relative to these revised age models.  The development of new chronologies must consider choices at the scale of individual chronological controls, at the scale of the site, and at regional scales. Using a matrix of parameters with empirical support, and choosing among multiple realizations is likely the most effective method for developing high quality chronologies for use in synthesis research. Because age-depth models require some degree of expert judgment, one general need is to better document age-depth models and parameters in the published literature and in community data resources such as Neotoma, both to increase reproducibility and to facilitate the quick regeneration of updated age models. Once models have been constructed, an importantgoal is the preservation and encoding of the choices that went into model development. High quality paleoecological research increasingly depends on high quality chronological support, and as such, researchers must pass on the information they have gained, in developing site level and regional chronologies, in a well supported and effectively communicated manner.

# Acknowledgements

This work is a contribution of the PalEON Project (http://paleon-project.org).  SJG would like to thank support from NSG, CEG and AMG. SJG is supported through NSF Grants NSF-1541002, NSF-1550855, NSF-1241868, and NSF-1550707.  This paper was improved through discussions with many in the paleoecological community, and would not have been possible without the significant contributions of all those who have contributed to the Neotoma Paleoecological Database.

# References
